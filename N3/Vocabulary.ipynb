{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Language Knowledge (Vocabulary)\n",
    "Duration: 30 minutes\n",
    "Content: This section tests your knowledge of Japanese vocabulary, including kanji readings, orthography, word formation, contextually-defined expressions, paraphrases, and usage\n",
    "It mainly composes following five categories:\n",
    "- ``Reading Kana`` (Pronunciation Questions): Given a kanji word, choose the correct kana reading.\n",
    "- `Writing Kanji` (Writing Questions): Given a word written in kana, choose the correct kanji representation.\n",
    "- `Word Meaning` Selection (Vocabulary Understanding): Choose the most suitable word to fill in the sentence from four options.\n",
    "- `Synonym Replacement`: Select a word that has the same or similar meaning as the underlined word.\n",
    "- `Vocabulary Usage`: Assess the usage of words in actual contexts, choosing the most appropriate word usage, including some common Japanese expressions or fixed phrases."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b011bdf967ca7ff"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import uuid\n",
    "from typing import *\n",
    "from langchain_openai import AzureOpenAI,AzureChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain_community.embeddings import XinferenceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage,RemoveMessage,HumanMessage,AIMessage,ToolMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional\n",
    "\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T16:32:16.096504700Z",
     "start_time": "2025-03-20T16:32:16.053649700Z"
    }
   },
   "id": "7f526a68a7e73a65"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "  expression reading\n0         偶々    たまたま\n1       それぞれ    それぞれ\n2         議論     ぎろん\n3         実現    じつげん\n4         機械     きかい",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>expression</th>\n      <th>reading</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>偶々</td>\n      <td>たまたま</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>それぞれ</td>\n      <td>それぞれ</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>議論</td>\n      <td>ぎろん</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>実現</td>\n      <td>じつげん</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>機械</td>\n      <td>きかい</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import N3 Vocabulary\n",
    "file_path = '../Vocab/n3.csv'\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "words = data.iloc[:, :2].sample(frac=1).reset_index(drop=True)\n",
    "# Display the content of the CSV file\n",
    "words.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T16:32:16.114505600Z",
     "start_time": "2025-03-20T16:32:16.061878700Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### load Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c1cdce8b1f57ef3"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "Missing credentials. Please pass one of `api_key`, `azure_ad_token`, `azure_ad_token_provider`, or the `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_AD_TOKEN` environment variables.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOpenAIError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[134]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m llm = \u001B[43mAzureChatOpenAI\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43mazure_endpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mhttps://tooldev-openai.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mapi_key\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mgpt-4o\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mapi_version\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m2025-01-01-preview\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject\\jlpt\\venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001B[39m, in \u001B[36mSerializable.__init__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args: Any, **kwargs: Any) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    124\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[31m[... skipping hidden 1 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject\\jlpt\\venv\\Lib\\site-packages\\langchain_openai\\chat_models\\azure.py:657\u001B[39m, in \u001B[36mAzureChatOpenAI.validate_environment\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    655\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.client:\n\u001B[32m    656\u001B[39m     sync_specific = {\u001B[33m\"\u001B[39m\u001B[33mhttp_client\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m.http_client}\n\u001B[32m--> \u001B[39m\u001B[32m657\u001B[39m     \u001B[38;5;28mself\u001B[39m.root_client = \u001B[43mopenai\u001B[49m\u001B[43m.\u001B[49m\u001B[43mAzureOpenAI\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mclient_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43msync_specific\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[32m    658\u001B[39m     \u001B[38;5;28mself\u001B[39m.client = \u001B[38;5;28mself\u001B[39m.root_client.chat.completions\n\u001B[32m    659\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.async_client:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject\\jlpt\\venv\\Lib\\site-packages\\openai\\lib\\azure.py:194\u001B[39m, in \u001B[36mAzureOpenAI.__init__\u001B[39m\u001B[34m(self, api_version, azure_endpoint, azure_deployment, api_key, azure_ad_token, azure_ad_token_provider, organization, project, websocket_base_url, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001B[39m\n\u001B[32m    191\u001B[39m     azure_ad_token = os.environ.get(\u001B[33m\"\u001B[39m\u001B[33mAZURE_OPENAI_AD_TOKEN\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    193\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m api_key \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m azure_ad_token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m azure_ad_token_provider \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m194\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m OpenAIError(\n\u001B[32m    195\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mMissing credentials. Please pass one of `api_key`, `azure_ad_token`, `azure_ad_token_provider`, or the `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_AD_TOKEN` environment variables.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    196\u001B[39m     )\n\u001B[32m    198\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m api_version \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    199\u001B[39m     api_version = os.environ.get(\u001B[33m\"\u001B[39m\u001B[33mOPENAI_API_VERSION\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mOpenAIError\u001B[39m: Missing credentials. Please pass one of `api_key`, `azure_ad_token`, `azure_ad_token_provider`, or the `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_AD_TOKEN` environment variables."
     ]
    }
   ],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://tooldev-openai.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview\",\n",
    "    api_key=\"\",\n",
    "    model_name=\"gpt-4o\",\n",
    "    api_version=\"2025-01-01-preview\",\n",
    "    temperature=0.5,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T16:32:16.237637200Z",
     "start_time": "2025-03-20T16:32:16.075100400Z"
    }
   },
   "id": "895a64c8ba51e354"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# llm = ChatBedrock(\n",
    "#     model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "#      # model_id=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "#     model_kwargs=dict(temperature=0.3),\n",
    "#     region = \"us-east-2\",\n",
    "#     aws_access_key_id=\"\",\n",
    "#     aws_secret_access_key=\"\"\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-20T16:32:16.217637700Z"
    }
   },
   "id": "5643fdb248144100"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-20T16:32:16.218638100Z"
    }
   },
   "id": "c81d15454f724b5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exam Paper Outline\n",
    "### A. overall thinking the structure of an exam\n",
    "1. distribution of the difficulty \n",
    "2. topics\n",
    "3. reasoning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "385c63b54b5c2a36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "instruction = \"\"\"\n",
    "Section 1: Vocabulary and Grammar\n",
    "    SubSection: \n",
    "        - Kanji reading: 1-10 questions\n",
    "        - Orthography: 1-10 questions\n",
    "        - Word formation: 1-10 questions\n",
    "        - Contextually-defined expressions: 1-10 questions\n",
    "        - Paraphrases: 1-10 questions\n",
    "        - Usage: 1-10 questions\n",
    "        - Sentential grammar (Selecting grammar form): 1-10 questions\n",
    "        - Sentential grammar (Sentence composition): 1-10 questions\n",
    "        - Text grammar: 1-10 questions\n",
    "Total Vocabulary and Grammar Questions: 25-35 questions\n",
    "\n",
    "Section 2: Reading Comprehension\n",
    "    SubSection:\n",
    "        - Short passages: only 1 topic for 5-8 questions\n",
    "        - Mid-size passages: only 1 topic for 4-6 questions\n",
    "        - Long passages: only 1 topic for 3-5 questions\n",
    "        - Information retrieval: only 1 topic for 3-5 questions\n",
    "Total Reading Comprehension Questions: 15-24 questions\n",
    "\n",
    "Section 3: Listening Comprehension\n",
    "    SubSection:\n",
    "        - Task-based comprehension: 5-8 questions\n",
    "        - Comprehension of key points: 5-8 questions\n",
    "        - Quick response: 5-8 questions\n",
    "        - Integrated comprehension: 3-5 questions\n",
    "Total Listening Comprehension Questions: 18-29 questions\n",
    "\"\"\"\n",
    "\n",
    "direct_gen_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            f\"You are a japanese teacher. Your job is to write an outline for a JLPT N3 level exam paper by randomly picking some of the topic list that user provided for different sections. The JLPT exam paper includes a mix of easy, moderate, and difficult questions to accurately assess the test-taker's proficiency across different aspects of the language.\"\n",
    "            f\"First, you should abide by the following exam instructions and decide content and number of questions in the each subsection.\"\n",
    "            f\"Second, the vocabulary should be restricted to N3 level, you can refer to the vocabulary in the word list\"\n",
    "            f\"Finally, write the outline of the examination paper and provide question topics according to the instructions.\"\n",
    "            f\"instruction: {instruction}, word list: {words}\",\n",
    "        ),\n",
    "        (\"user\", \"topic list: {topic}\"),\n",
    "    ]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-20T16:32:16.218638100Z"
    }
   },
   "id": "e339295a858fb5f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Strcuture"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fed5f032dadafac1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class QuestionTopic(BaseModel):\n",
    "    question: str = Field(..., title=\"keyword of the question\")\n",
    "    \n",
    "    \n",
    "\n",
    "class Subsection(BaseModel):\n",
    "    subsection_title: str = Field(..., title=\"Topic of the subsection\")\n",
    "    description: str = Field(..., title=\"giving the number of questions\")\n",
    "    question_topics: Optional[List[QuestionTopic]] = Field(\n",
    "        default_factory=list,\n",
    "        title=\"a number of questions according to the section requirements\",\n",
    "    )\n",
    "    \n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        question_topics_str = \"\\n\".join(\n",
    "            f\"- **{qt.question}**\" for qt in self.question_topics\n",
    "        )\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.description}\\n\\n{question_topics_str}\".strip()\n",
    "\n",
    "class Section(BaseModel):\n",
    "    section_title: str = Field(..., title=\"Title of the section\")\n",
    "    # description: str = Field(..., title=\"Ideas of this section\")\n",
    "    subsections: Optional[List[Subsection]] = Field(\n",
    "        default_factory=list,\n",
    "        title=\"Titles and reason for each subsection of the JLPT exam page.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            subsection.as_str for subsection in self.subsections or []\n",
    "        )\n",
    "        return f\"## {self.section_title}\\n\\n{subsections}\".strip()\n",
    "\n",
    "\n",
    "class Outline(BaseModel):\n",
    "    page_title: str = Field(..., title=\"Title of the JLPT exam page\")\n",
    "    sections: List[Section] = Field(\n",
    "        default_factory=list,\n",
    "        title=\"Titles and descriptions for each section of the JLPT exam paper.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        sections = \"\\n\\n\".join(section.as_str for section in self.sections)\n",
    "        return f\"# {self.page_title}\\n\\n{sections}\".strip()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-20T16:32:16.219639500Z"
    }
   },
   "id": "39329a71b16d2400"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_topic = \"\"\"\n",
    "Section 1 - Vocabulary and Grammar: \n",
    "店で価格を尋ねる | 購入したい商品の説明 | 割引交渉 | レストランで食べ物を注文する | 食事の好みについて話す | 料理を褒める | 道を尋ねる | 交通手段について話す | 交通状況について話す | タクシーを予約する | 電車の切符を買う | バスの時刻表を尋ねる | 通勤について説明する | 天気の状況について話す | 週末の予定について話す | おすすめを尋ねる | ショッピング体験を説明する | 支払い方法について話す | 領収書を求める | お気に入りのレストランについて話す | 趣味について話す | 仕事のプロジェクトについて話す | 家族について話す | 旅行の計画について話す | 最近の映画について話す | 本について話す | スポーツについて話す | 健康とフィットネスについて話す | 技術について話す | 時事問題について話す | 音楽について話す | 芸術と文化について話す | 教育について話す | キャリア目標について話す | 個人的な成果について話す | 課題と解決策について話す | 将来の抱負について話す | お気に入りのテレビ番組について話す | ペットについて話す | ガーデニングについて話す | 家の改善について話す | ファッションとスタイルについて話す | 環境問題について話す | ボランティア活動について話す | 地域のイベントについて話す\n",
    "\"\"\"\n",
    "\n",
    "generate_outline_direct = direct_gen_outline_prompt | llm.with_structured_output(Outline,include_raw=True)\n",
    "initial_outline = generate_outline_direct.invoke({\"topic\": example_topic})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-20T16:32:16.220638200Z"
    }
   },
   "id": "a052e26f8a90f653"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(initial_outline)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-20T16:32:16.221637800Z"
    }
   },
   "id": "e4498efbce130647"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown(initial_outline.as_str))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-20T16:32:16.222638100Z"
    }
   },
   "id": "b1eae0f032de41e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kanji 读假名（读音问题）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5795bb3d95c0cc50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# Graph state\n",
    "class QuestionState(TypedDict):\n",
    "    topic: str\n",
    "    question: str\n",
    "    improved_question: str\n",
    "    final_question: str\n",
    "\n",
    "\n",
    "kanji_example = \"\"\"\n",
    "1) いま 店の まえにいます。\n",
    "1 いえ\n",
    "2 えき\n",
    "3 みせ\n",
    "4 へや\n",
    "2) たなかさんは いま 外国に います。\n",
    "1 がいしゃ\n",
    "2 かいしゃ\n",
    "3 かいこく 4 がいこく\n",
    "3) さとうさんは 話が じょうずです。\n",
    "1 うた\n",
    "2 はなし\n",
    "3 え\n",
    "4 じ\n",
    "4) はやしさんも 読んで ください。\n",
    "1 あそんで\n",
    "2 ならんで\n",
    "3 よんで\n",
    "4 えらんで\n",
    "5) あたらしい こうえんは まちの 北がわに あります。\n",
    "1 ひがしがわ\n",
    "2 みなみがわ\n",
    "3 にしがわ\n",
    "4 きたがわ\n",
    "6) わたしは 九月に けっこんします。。\n",
    "1 くがつ\n",
    "2 きゅうがつ\n",
    "3 くげつ\n",
    "4 きゅうげつ\n",
    "7) きのう 来なかった ひとは だれですか。\n",
    "1 きなかった\n",
    "2 こなかった\n",
    "3 いなかった \n",
    "4 ねなかった\n",
    "\"\"\"\n",
    "\n",
    "print(words)\n",
    "\n",
    "# Nodes\n",
    "def generate_question(state: QuestionState):\n",
    "    \"\"\"First LLM call to generate initial question\"\"\"\n",
    "\n",
    "    msg = llm.invoke(f\"You are a japanese teacher. Your job is to write 5 vocabulary questions for candidate to identify kanji characters and their meanings for a JLPT N3 level exam paper by topics that user provided in the topic list. This includes recognizing kanji in context, such as in sentences or phrase. Don't replace kanji part and only substitute in the options. The JLPT exam paper includes a mix of easy, moderate, and difficult questions to accurately assess the test-taker's proficiency across different aspects of the language.\"\n",
    "            f\"The vocabulary should be restricted to N3 level, you can refer to the vocabulary in the word list, choosing random words for the questions\"\n",
    "            f\"please refer the question examples following the formal exam paper\"\n",
    "            f\"append the correct answer and explanation of main challenges and why teacher asks this question to candidate in chinese at each question\"\n",
    "            f\"Finally, beautify markdown format\"\n",
    "            f\"topic list: {state['topic']}\"\n",
    "            f\"word list: {words}\"\n",
    "            f\"formal exam paper: {kanji_example}\")\n",
    "    \n",
    "    return {\"question\": msg.content}\n",
    "\n",
    "\n",
    "# Build workflow\n",
    "kanji_workflow = StateGraph(QuestionState)\n",
    "\n",
    "# Add nodes\n",
    "kanji_workflow.add_node(\"generate_question\", generate_question)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "kanji_workflow.add_edge(START, \"generate_question\")\n",
    "kanji_workflow.add_edge(\"generate_question\", END)\n",
    "\n",
    "# Compile\n",
    "kanji_graph = kanji_workflow.compile()\n",
    "\n",
    "# Show workflow\n",
    "display(Image(kanji_graph.get_graph().draw_png()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-20T16:32:16.222638100Z"
    }
   },
   "id": "1a966afd733d860d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Invoke\n",
    "kanji = kanji_graph.invoke({\"topic\": \"個人的な成果について話す | 課題と解決策について話す | 将来の抱負について話す | お気に入りのテレビ番組について話す  | 食事の好みについて話す \"})\n",
    "display(Markdown(kanji[\"question\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-20T16:32:16.223638800Z"
    }
   },
   "id": "3c2e1e740fbe6971"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-20T16:32:16.224639900Z"
    }
   },
   "id": "553844c1e99d121c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-03-20T16:32:16.225638900Z"
    }
   },
   "id": "c778d8e10606427f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
