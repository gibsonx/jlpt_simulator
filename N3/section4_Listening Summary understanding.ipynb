{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b011bdf967ca7ff",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Language Knowledge (Vocabulary)\n",
    "Duration: 30 minutes\n",
    "Content: This section tests your knowledge of Japanese vocabulary, including kanji readings, orthography, word formation, contextually-defined expressions, paraphrases, and usage\n",
    "It mainly composes following five categories:\n",
    "- ``Reading Kana`` (Pronunciation Questions): Given a kanji word, choose the correct kana reading.\n",
    "- `Writing Kanji` (Writing Questions): Given a word written in kana, choose the correct kanji representation.\n",
    "- `Word Meaning` Selection (Vocabulary Understanding): Choose the most suitable word to fill in the sentence from four options.\n",
    "- `Synonym Replacement`: Select a word that has the same or similar meaning as the underlined word.\n",
    "- `Vocabulary Usage`: Assess the usage of words in actual contexts, choosing the most appropriate word usage, including some common Japanese expressions or fixed phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f526a68a7e73a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:46.881337200Z",
     "start_time": "2025-04-12T09:05:46.846841100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "import uuid\n",
    "from typing import *\n",
    "from langchain_openai import AzureOpenAI,AzureChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from dotenv import load_dotenv\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain_community.embeddings import XinferenceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage,RemoveMessage,HumanMessage,AIMessage,ToolMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain.schema import Document\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58607e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://ai-rolandaws880125ai409947751408.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview\",\n",
    "    api_key=os.environ[\"AZURE_API_KEY\"],\n",
    "    model_name=\"gpt-4o\",\n",
    "    api_version=\"2025-01-01-preview\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "aws_llm = ChatBedrock(\n",
    "    # model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "     model_id=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    model_kwargs=dict(temperature=0.5),\n",
    "    region = \"us-east-2\",\n",
    "    aws_access_key_id=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    aws_secret_access_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:46.893687800Z",
     "start_time": "2025-04-12T09:05:46.853897400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import N3 Vocabulary\n",
    "file_path = '../Vocab/n3.csv'\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "words = data.iloc[:, :2].sample(frac=1).reset_index(drop=True)\n",
    "# Display the content of the CSV file\n",
    "words.head()\n",
    "vocab_dict = words.set_index(words.columns[0])[words.columns[1]].to_dict()\n",
    "vocab_dict = json.dumps(vocab_dict, ensure_ascii=False, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1cdce8b1f57ef3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c63b54b5c2a36",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Exam Paper Outline\n",
    "### A. overall thinking the structure of an exam\n",
    "1. distribution of the difficulty \n",
    "2. topics\n",
    "3. reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed5f032dadafac1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Strcuture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5795bb3d95c0cc50",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Kanji 读假名（读音问题）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "252ffacd6ebb7b37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:46.893687800Z",
     "start_time": "2025-04-12T09:05:46.867091900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def online_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---WEB SEARCH---\")\n",
    "    \n",
    "    topic = state['messages'][0].content\n",
    "    \n",
    "    tavily_search_tool = TavilySearch(\n",
    "        max_results=5,\n",
    "        topic=\"news\",\n",
    "        days=1\n",
    "    )\n",
    "    # Web search\n",
    "    docs = tavily_search_tool.invoke({\"query\": topic})\n",
    "    \n",
    "    print(docs)\n",
    "\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs[\"results\"]])\n",
    "    \n",
    "    print(\"Web results: \", web_results)\n",
    "\n",
    "    return {\"documents\": web_results, \"topic\": topic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a966afd733d860d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:46.917155100Z",
     "start_time": "2025-04-12T09:05:46.871842700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# Graph state\n",
    "class QuestionState(TypedDict):\n",
    "    topic: str\n",
    "    question: str\n",
    "    documents: str\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "example = \"\"\"\n",
    "問題3  \n",
    "  \n",
    "1番 正解: 2  \n",
    "会話内容:\n",
    "日本語学校で女の留学生と男の留学生が話しています。  \n",
    "- 女: 来月で佐藤先生、学校を辞めちゃうんだよね。  \n",
    "- 男: 寂しくなるね。  \n",
    "- 女: うん。ねえ、クラスのみんなで先生に何か記念になるものをあげたいね。  \n",
    "- 男: あ、いいね。何か身に付けるものとか?  \n",
    "- 女: 先生おしゃれだし、そういうの選ぶの難しくない? それより私たちで何か作ろうよ。  \n",
    "- 男: あ、メッセージカードは? クラスのみんなにも書いてもらおうよ。  \n",
    "- 女: じゃ、スポーツ大会の時に撮ったクラスの集合写真を真ん中に貼って、周りにメッセージを書いてもらう?  \n",
    "- 男: いいね。皆にももらえるといいね。明日、休み時間にクラスのみんなに話してみよう。  \n",
    "  \n",
    "2人は何について話していますか?  \n",
    "1. 先生が学校を辞める理由    \n",
    "2. 先生に贈る物    \n",
    "3. クラスからのメッセージ    \n",
    "4. 先生との思い出    \n",
    "  \n",
    "---  \n",
    "  \n",
    "2番 正解: 1  \n",
    "会話内容:\n",
    "ラジオでアナウンサーが女の人にインタビューしています。  \n",
    "- 男: 高橋さんのグループは20年前から緑山に関わっていらっしゃるそうですね。  \n",
    "- 女: はい、私たちは緑山の自然を未来に残したいと考えています。緑山の木は、ほとんどは自然のものなんですが、商業目的で木が切られて、その後、新しく植えられたところもあるんです。  \n",
    "- 男: そうなんですか。  \n",
    "- 女: 人の手で植えられた木は世話をしないと細く、弱くなります。根も強くないので大雨や強い風で倒れたり、流されたりしてしまうこともあって、山全体にも影響が出てきます。そうならないように細い枝を落としたり、周りの草を取ったりして1本1本世話をし、木を育てています。  \n",
    "  \n",
    "女の人は何について話していますか?  \n",
    "1. 緑山の自然を守る活動    \n",
    "2. 緑山の木が減っている原因    \n",
    "3. 自然に育った木の特徴    \n",
    "4. 山に木を植える方法   \n",
    "  \n",
    "---  \n",
    "  \n",
    "3番 正解: 2  \n",
    "会話内容:\n",
    "ラジオで男の人が話しています。  \n",
    "- 男: 僕、わさびが好きでお寿司や刺身にたくさん付けて食べるのが好きなんですよ。わさびって食べると鼻が痛くなったり、涙が出たりして苦手な人もいるかもしれませんけど、魚の匂いを消してくれたり、食べ物が悪くなるのを防いでくれたりするんですよね。最近、雑誌で読んだんですが、わさびを食べると食欲が出たり、風邪を引きにくくなったりするなど健康にもいいということが研究によってわかってきたそうです。  \n",
    "   \n",
    "男の人は何について話していますか?  \n",
    "1. わさびを好きになったわけ    \n",
    "2. わさびの効果    \n",
    "3. わさびが苦手な人が多い理由    \n",
    "4. わさびのおいしさの研究    \n",
    "\"\"\"\n",
    "\n",
    "# Nodes\n",
    "def question_draft_generator(state: QuestionState):\n",
    "    \"\"\"First LLM call to generate initial question\"\"\"\n",
    "    print(\"---Generator----\")\n",
    "        \n",
    "    search_result = state['documents'],\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"\n",
    "                    You are a Japanese teacher. Your job is to write a listening question for candidates to prepare  the original text and options for the listening dialogue based on the reference format. Students need to listen to monologues or dialogues, summarize their understanding, and choose options that match the meaning of the question based on the listening content. There will be 3-5 back and forth dialogues, containing about 150-250 words and 4 options. After listening to a conversation, I often ask someone in the conversation what they are going to do next. Only refer to the format, not the content. The JLPT exam paper includes a mix of easy, moderate, and difficult questions to accurately assess the test-taker’s proficiency across different aspects of the language.\n",
    "                    The vocabulary should be restricted to N3 level, use the vocabulary in the `Dictionary` as much as you can.\n",
    "                    Please refer to the question examples following the formal exam paper.\n",
    "                    Append the correct answer and explanation of the main challenges on why the teacher asks this question to the candidate in simplified Chinese at each question.\n",
    "                    Finally, output beautiful markdown format.\n",
    "                    Dictionary: {vocab_dict}\n",
    "                    Search result: {search_result}\n",
    "                    Formal exam paper: {example}\n",
    "                \"\"\"\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    \n",
    "    input = { \"topic\" : state['topic'],\n",
    "              \"search_result\": search_result, \n",
    "              \"vocab_dict\": vocab_dict,\n",
    "              \"example\": example,\n",
    "              \"messages\": state[\"messages\"]\n",
    "              }\n",
    "    # final_message = prompt.format_messages(**input)\n",
    "    # print(final_message)\n",
    "    \n",
    "    generate = prompt | azure_llm\n",
    "    \n",
    "    msg = generate.invoke(input=input)\n",
    "    \n",
    "    \n",
    "    return {\"question\": msg.content, \"messages\": [AIMessage(content=msg.content)] }\n",
    "\n",
    "\n",
    "def reflection_node(state: QuestionState) -> QuestionState:\n",
    "    print(\"---REVISOR---\")\n",
    "    \n",
    "    # Other messages we need to adjust\n",
    "    cls_map = {\"ai\": HumanMessage, \"human\": AIMessage}\n",
    "    # First message is the original user request. We hold it the same for all nodes\n",
    "    translated = [state[\"messages\"][0]] + [\n",
    "        cls_map[msg.type](content=msg.content) for msg in state[\"messages\"][1:]\n",
    "    ]\n",
    "\n",
    "    reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"you are a Japanese language educator reviewing a JLPT exam paper. Generate critique and recommendations for the user's submission.\n",
    "            the review focuses on content accuracy and question quality. \n",
    "            - For content accuracy, you must verify that the grammar and vocabulary questions accurately reflect the appropriate JLPT N3 level, ensuring the reading passages are clear, relevant, and appropriately challenging. \n",
    "            - For question quality, you must ensure all questions are clearly worded and free from ambiguity to comprehensively assess different language skills, and confirm that the difficulty level of the questions matches the intended JLPT N3 level.\n",
    "            - During detailed refinement, you check the format and presentation of the paper, ensuring it is well-organized and the instructions are clear and concise. you also ensure the content is culturally appropriate and relevant to Japanese language and culture.\n",
    "            - Finally, you make give feedback, providing detailed recommendations, including requests.If you think the exam paper is good enough, you just say \"GOOD ENOUGH\"\n",
    "            \"\"\"\n",
    "        ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    reflect = reflection_prompt | azure_llm\n",
    "    \n",
    "    res = reflect.invoke(translated)\n",
    "    \n",
    "    print(res.content)\n",
    "    \n",
    "    # We treat the output of this as human feedback for the generator\n",
    "    return {\"messages\": [HumanMessage(content=res.content)]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30e802dc904d791c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:47.226967100Z",
     "start_time": "2025-04-12T09:05:46.881337200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build workflow\n",
    "builder = StateGraph(QuestionState)\n",
    "\n",
    "builder.add_node(\"online_search\", online_search)\n",
    "builder.add_node(\"generator\", question_draft_generator)\n",
    "builder.add_node(\"reflector\", reflection_node)\n",
    "# Add nodes\n",
    "\n",
    "def should_continue(state: QuestionState):\n",
    "    if state[\"messages\"]:\n",
    "        if len(state[\"messages\"]) > 6: \n",
    "            print(\"--- Reach the Maximum Round ---\")\n",
    "            return END\n",
    "        elif \"GOOD ENOUGH\" in state[\"messages\"][-1].content:\n",
    "            print(\"--- AI Reviser feels Good Enough ---\")\n",
    "            return END\n",
    "    return \"generator\"\n",
    "\n",
    "# Add edges to connect nodes\n",
    "builder.add_edge(START, \"online_search\")\n",
    "builder.add_edge(\"online_search\", \"generator\")\n",
    "builder.add_edge(\"generator\",\"reflector\")\n",
    "# \n",
    "builder.add_conditional_edges(\"reflector\", should_continue)\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile\n",
    "kanji_graph = builder.compile()\n",
    "\n",
    "# Show workflow\n",
    "# display(Image(kanji_graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eec5f157c924be8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:47.233071800Z",
     "start_time": "2025-04-12T09:05:47.226967100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HW-BK003\\AppData\\Local\\Temp\\ipykernel_20104\\846002302.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  word = f\"{row[0]}({row[1]})\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'タオル(タオル)'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = words.iloc[1]\n",
    "word = f\"{row[0]}({row[1]})\"\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c2e1e740fbe6971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:47.238098800Z",
     "start_time": "2025-04-12T09:05:47.233071800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Debug the Conversation\n",
    "# for event in kanji_graph.stream(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             HumanMessage(\n",
    "#                 content=word\n",
    "#             )\n",
    "#         ],\n",
    "#     },\n",
    "#     config={\"configurable\": {\"thread_id\": \"1\"}},\n",
    "# ):\n",
    "#     print(event)\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "553844c1e99d121c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:06:11.173729Z",
     "start_time": "2025-04-12T09:05:47.238098800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---WEB SEARCH---\n",
      "{'query': 'タオル(タオル)', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'タオル - Wikipedia', 'url': 'https://ja.wikipedia.org/wiki/タオル', 'content': 'タオル （英: towel[1]）とは、 タオル地 （テリータオル地）と呼ばれる パイル の構造を有する繊維製品 [2]。 サイズ・用途によってフェイスタオル、バスタオル、ビーチタオル、スポーツタオルなどに分類できる。', 'score': 0.9237645, 'raw_content': None}, {'title': '【楽天市場】タオルの通販', 'url': 'https://search.rakuten.co.jp/search/mall/タオル/', 'content': '楽天市場-「タオル」1,856,294件 人気の商品を価格比較・ランキング･レビュー・口コミで検討できます。ご購入でポイント取得がお得。セール商品・送料無料商品も多数。「あす楽」なら翌日お届けも可能です。', 'score': 0.445506, 'raw_content': None}, {'title': 'Amazon.co.jp: タオル', 'url': 'https://www.amazon.co.jp/タオル/s?k=タオル', 'content': '【Amazon.co.jp限定】タオル研究所 [ボリュームリッチ] #003 フェイスタオル チャコールグレー 5枚セット ホテル仕様 ふかふか 高速吸水 綿100% 耐久性 毛羽落ち少ない 【選べる10色】 Japan Technology', 'score': 0.31605303, 'raw_content': None}, {'title': '【徹底比較】タオルのおすすめ人気ランキング【2025年】', 'url': 'https://my-best.com/13020', 'content': 'Lumimiの「バスタオル」は、 毛羽落ちの少ないマイクロファイバーのバスタオルがほしい人におすすめ です。 検証で3回洗濯したあとの毛羽落ちの割合は0.05％と低く、毛羽が気になることはほとんどないでしょう。', 'score': 0.27468732, 'raw_content': None}, {'title': 'タオルソムリエが解説! タオルの選び方＆おすすめ25選 | Elle Decor [エル・デコ]', 'url': 'https://www.elle.com/jp/decor/decor-interior-design/a37593846/6uy-towel-21-0928/', 'content': 'タオルドクターに、タオルの賢い選び方から洗濯の仕方、ダメになってしまったタオルのリカバリー方法までをASK!', 'score': 0.22916451, 'raw_content': None}], 'response_time': 1.74}\n",
      "Web results:  タオル （英: towel[1]）とは、 タオル地 （テリータオル地）と呼ばれる パイル の構造を有する繊維製品 [2]。 サイズ・用途によってフェイスタオル、バスタオル、ビーチタオル、スポーツタオルなどに分類できる。\n",
      "楽天市場-「タオル」1,856,294件 人気の商品を価格比較・ランキング･レビュー・口コミで検討できます。ご購入でポイント取得がお得。セール商品・送料無料商品も多数。「あす楽」なら翌日お届けも可能です。\n",
      "【Amazon.co.jp限定】タオル研究所 [ボリュームリッチ] #003 フェイスタオル チャコールグレー 5枚セット ホテル仕様 ふかふか 高速吸水 綿100% 耐久性 毛羽落ち少ない 【選べる10色】 Japan Technology\n",
      "Lumimiの「バスタオル」は、 毛羽落ちの少ないマイクロファイバーのバスタオルがほしい人におすすめ です。 検証で3回洗濯したあとの毛羽落ちの割合は0.05％と低く、毛羽が気になることはほとんどないでしょう。\n",
      "タオルドクターに、タオルの賢い選び方から洗濯の仕方、ダメになってしまったタオルのリカバリー方法までをASK!\n",
      "---Generator----\n",
      "---REVISOR---\n",
      "### Review of JLPT N3 Exam Question: タオルについて\n",
      "\n",
      "#### Content Accuracy:\n",
      "1. **Grammar and Vocabulary**: The dialogue is appropriate for the JLPT N3 level. The vocabulary includes terms such as \"フェイスタオル,\" \"バスタオル,\" \"スポーツタオル,\" and \"用途,\" which are relevant and not overly advanced for N3 learners. The grammar structures used (e.g., \"用途に応じて分けられる\" and \"素材もいろいろあって\") are consistent with N3-level patterns, such as explanatory clauses and compound sentences.\n",
      "2. **Relevance**: The topic of \"タオル\" and its types is culturally neutral and universally relatable, making it suitable for learners of Japanese from diverse backgrounds. It also introduces practical vocabulary that could be useful in everyday life, aligning with the goals of the JLPT.\n",
      "3. **Challenge Level**: The dialogue provides an appropriate level of challenge for N3. It requires learners to identify the main topic and understand specific details, such as the different types of towels and their uses.\n",
      "\n",
      "#### Question Quality:\n",
      "1. **Clarity**: The question is clearly worded and free from ambiguity. The options provided (e.g., \"タオルの歴史,\" \"タオルの種類と用途\") are distinct and do not overlap, which ensures a fair evaluation of the learner's comprehension skills.\n",
      "2. **Focus**: The question effectively assesses listening comprehension, specifically the ability to identify the central theme of a conversation. It avoids unnecessary complexity and focuses on the core content of the dialogue.\n",
      "3. **Difficulty Level**: The question matches the intended JLPT N3 difficulty level. It requires learners to process the dialogue and distinguish between relevant and irrelevant information, a skill that is essential for this level.\n",
      "\n",
      "#### Format and Presentation:\n",
      "1. **Organization**: The format of the question is well-structured. The dialogue is presented in a logical order, and the question follows immediately after, ensuring that learners can focus on the task without confusion.\n",
      "2. **Instructions**: The instructions are concise and clear. Learners are asked to identify the main topic of the conversation, which is a standard type of question for the JLPT.\n",
      "3. **Cultural Appropriateness**: The content is culturally appropriate and does not include any potentially sensitive or controversial topics. The discussion about towels is neutral and practical.\n",
      "\n",
      "#### Recommendations:\n",
      "1. **Enhancing Vocabulary Range**: To further challenge learners and enrich their vocabulary, consider including more descriptive terms about towel materials or properties (e.g., \"吸水性が高い\" could be expanded to include \"速乾性\" or \"抗菌性\").\n",
      "2. **Expanding Context**: While the current dialogue is sufficient, adding a short follow-up question that requires learners to infer or predict (e.g., \"どんなタオルを買うと思いますか?\") could deepen the assessment of comprehension skills.\n",
      "3. **Formatting Suggestion**: Consider bolding key terms in the dialogue (e.g., \"用途,\" \"吸水性\") to subtly guide learners toward the main points without giving away the answer.\n",
      "\n",
      "### Final Verdict:\n",
      "GOOD ENOUGH\n",
      "--- AI Reviser feels Good Enough ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# 問題\n",
       "\n",
       "1番 正解: 2  \n",
       "会話内容:  \n",
       "日本語学校で女の留学生と男の留学生が話しています。  \n",
       "\n",
       "- 女: 最近、タオルについて調べているんだけど、いろいろな種類があることに驚いたよ。  \n",
       "- 男: どんな種類があるの?  \n",
       "- 女: フェイスタオル、バスタオル、ビーチタオル、スポーツタオルなど用途に応じて分けられるんだって。  \n",
       "- 男: 確かに、スポーツをするときは吸水性が高いタオルが必要だよね。  \n",
       "- 女: そうそう。しかも、タオルの素材もいろいろあって、綿100%のものや毛羽落ちが少ないマイクロファイバーのものがあるんだって。  \n",
       "- 男: へえ、用途によって選ぶのが大事なんだね。僕も新しいバスタオルを買おうかな。  \n",
       "\n",
       "2人は何について話していますか?  \n",
       "1. タオルの歴史  \n",
       "2. タオルの種類と用途  \n",
       "3. タオルの洗濯方法  \n",
       "4. タオルの価格  \n",
       "\n",
       "---\n",
       "\n",
       "### 答案と解析\n",
       "\n",
       "**正解: 2**  \n",
       "**解析:**  \n",
       "这道题考察学生听力理解能力，尤其是抓住对话核心内容的能力。对话中提到“最近、タオルについて調べている”、“フェイスタオル、バスタオル、ビーチタオル、スポーツタオルなど用途に応じて分けられる”以及“素材もいろいろあって”这些关键词，明确说明对话的主题是关于“タオルの種類と用途”。  \n",
       "\n",
       "**主要难点:**  \n",
       "学生需要能够从对话中提取具体信息并总结内容，同时避免被其他选项中的干扰信息迷惑，例如“洗濯方法”和“価格”虽然也可能与タオル有关，但并非对话的核心内容。  \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kanji = kanji_graph.invoke(\n",
    "    {\n",
    "       \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=word\n",
    "                )\n",
    "            ],\n",
    "        },\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "display(Markdown(kanji[\"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778d8e10606427f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:06:11.182472400Z",
     "start_time": "2025-04-12T09:06:11.173729Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
