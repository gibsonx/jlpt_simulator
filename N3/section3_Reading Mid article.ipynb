{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b011bdf967ca7ff",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Language Knowledge (Vocabulary)\n",
    "Duration: 30 minutes\n",
    "Content: This section tests your knowledge of Japanese vocabulary, including kanji readings, orthography, word formation, contextually-defined expressions, paraphrases, and usage\n",
    "It mainly composes following five categories:\n",
    "- ``Reading Kana`` (Pronunciation Questions): Given a kanji word, choose the correct kana reading.\n",
    "- `Writing Kanji` (Writing Questions): Given a word written in kana, choose the correct kanji representation.\n",
    "- `Word Meaning` Selection (Vocabulary Understanding): Choose the most suitable word to fill in the sentence from four options.\n",
    "- `Synonym Replacement`: Select a word that has the same or similar meaning as the underlined word.\n",
    "- `Vocabulary Usage`: Assess the usage of words in actual contexts, choosing the most appropriate word usage, including some common Japanese expressions or fixed phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f526a68a7e73a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T04:52:51.327395Z",
     "start_time": "2025-03-21T04:52:51.315832Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import uuid\n",
    "from typing import *\n",
    "from langchain_openai import AzureOpenAI,AzureChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain_community.embeddings import XinferenceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage,RemoveMessage,HumanMessage,AIMessage,ToolMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T04:52:51.375033Z",
     "start_time": "2025-03-21T04:52:51.356406Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expression</th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>近視</td>\n",
       "      <td>きんし</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>完成</td>\n",
       "      <td>かんせい</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>食品</td>\n",
       "      <td>しょくひん</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>清む</td>\n",
       "      <td>すむ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>炒める</td>\n",
       "      <td>いためる</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  expression reading\n",
       "0         近視     きんし\n",
       "1         完成    かんせい\n",
       "2         食品   しょくひん\n",
       "3         清む      すむ\n",
       "4        炒める    いためる"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import N3 Vocabulary\n",
    "file_path = '../Vocab/n3.csv'\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "words = data.iloc[:, :2].sample(frac=1).reset_index(drop=True)\n",
    "# Display the content of the CSV file\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1cdce8b1f57ef3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895a64c8ba51e354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T04:52:52.986251Z",
     "start_time": "2025-03-21T04:52:51.377041Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# azure_llm = AzureChatOpenAI(\n",
    "#     azure_endpoint=\"https://tooldev-openai.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview\",\n",
    "#     api_key=os.environ[\"AZURE_API_KEY\"],\n",
    "#     model_name=\"gpt-4o\",\n",
    "#     api_version=\"2025-01-01-preview\",\n",
    "#     temperature=0.5,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5643fdb248144100",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T04:52:53.325835Z",
     "start_time": "2025-03-21T04:52:52.988251Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aws_llm = ChatBedrock(\n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "     # model_id=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    model_kwargs=dict(temperature=0.3),\n",
    "    region = \"us-east-2\",\n",
    "    aws_access_key_id=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    aws_secret_access_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed5f032dadafac1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Question Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5795bb3d95c0cc50",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Kanji 读假名（读音问题）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a966afd733d860d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T04:55:02.288686Z",
     "start_time": "2025-03-21T04:55:01.768183Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     expression reading\n",
      "0            近視     きんし\n",
      "1            完成    かんせい\n",
      "2            食品   しょくひん\n",
      "3            清む      すむ\n",
      "4           炒める    いためる\n",
      "...         ...     ...\n",
      "2134         地味      じみ\n",
      "2135       なぜなら    なぜなら\n",
      "2136         不安     ふあん\n",
      "2137         公演    こうえん\n",
      "2138         性質    せいしつ\n",
      "\n",
      "[2139 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# Graph state\n",
    "class QuestionState(TypedDict):\n",
    "    topic: str\n",
    "    question: str\n",
    "    improved_question: str\n",
    "    final_question: str\n",
    "\n",
    "\n",
    "kanji_example = \"\"\"\n",
    " 問題５\n",
    "\n",
    " (1)\n",
    "日本に留学に来る前、母が持っていきなさいと言って、私の国でよく売っている粉の香辛料をくれました。私が普段あまり使わないものでしたが、役に立つかもしれないと母が言うので、荷物に入れました。最近、それが本当に役に立ちました。  \n",
    "先月、①ちょっと困ったことがありました。ある留学生交流会に、国の料理を作ってきてほしいと言われたのです。私にも得意な料理はあるのですが、日本では買えない材料を使うので作れません。そのとき、私はあの香辛料を思い出したのです。  \n",
    "私は、肉と卵を使ってチャーハンを作り、香辛料をかけてみました。すると、日本によくある普通のチャーハンが、私の国らしい味と香りの②特別なチャーハンになったのです。交流会でも、みんな、おいしいおいしいと言って食べてくれて、安心しました。  \n",
    "あのとき、母はこういうことを予想していたのでしょうか。明日電話するので、③母に聞いてみようと思います。\n",
    "\n",
    "---\n",
    "\n",
    "27. ①ちょっと困ったことがありましたとあるが、「私」が困ったのはなぜか。**  \n",
    "1. 母に、普段あまり使わない香辛料を持っていくように言われたから  \n",
    "2. 得意な料理がないのに、国の料理を作ってきてほしいと言われたから  \n",
    "3. 国の料理を作ってきてほしいと言われたが、日本では得意な料理が作れないから  \n",
    "4. チャーハンが作れないのに、チャーハンを作ってきてほしいと言われたから  \n",
    "\n",
    "28. ②特別なチャーハンとは、どのようなチャーハンか。**  \n",
    "1. 日本で売っている材料でチャーハンを作って、国の香辛料をかけたもの  \n",
    "2. 日本で売っている材料でチャーハンを作って、日本の香辛料をかけたもの  \n",
    "3. 国から持ってきた材料でチャーハンを作って、国の香辛料をかけたもの  \n",
    "4. 国から持ってきた材料でチャーハンを作って、日本の香辛料をかけたもの  \n",
    "\n",
    "29. ③母に聞いてみようと思いますとあるが、「私」はどのようなことを聞くと考えられるか。**  \n",
    "1. 国の香辛料がどうして日本で役に立つと思ったのか  \n",
    "2. どんな料理を作るときに国の香辛料を使えばいいのか  \n",
    "3. 「私」が日本に留学することを予想していたかどうか\n",
    "\n",
    " 問題５\n",
    "\n",
    " (2)\n",
    "服や靴を作っている、ある海外のファッションの会社が始めた活動がある。まず、漁師たち（魚をとって生活している人たち）に組んで、魚をとるときに網にとれるごみを港に持ち帰ってもらう。そして、会社がそのごみを回収・分割し、その中のプラスチックを縫紐に変え、服や靴にして売るというリサイクル活動である。  \n",
    "以前、漁師たちはごみがとれても海に戻していた。港に持ち帰ると捨てるのにお金がかかるからだ。この活動は、漁師にとっても、自分のお金を使わずに海をきれいにできる良さがある。  \n",
    "これらの服や靴は最近日本でも売られ始めた。デザインも悪くない。消費者の意識が変化している今、日本でもきっと受け入れられるだろう。\n",
    "\n",
    "---\n",
    "\n",
    "30. 「海外のファッションの会社」がしていることとして、合っているのはどれか。**  \n",
    "1. 漁師たちと一緒に、海にごみをとりに行っている  \n",
    "2. 漁師たちから港でごみを受け取って、他に持ち帰っている  \n",
    "3. 漁師たちがプラスチックごみから服や靴を作るのを助けて、それを売っている  \n",
    "4. 漁師たちが海でとったプラスチックごみを利用して、服や靴を作っている  \n",
    "\n",
    "31. 漁師たちは、なぜ「海外のファッションの会社」が始めた活動に参加するのか。**  \n",
    "1. ほかの漁師たちとの協力関係ができるから  \n",
    "2. 自分たちのお金をかけずに、海のごみを減らすことができるから  \n",
    "3. 魚をとるためにかかっていたお金を減らすことができるから  \n",
    "4. 自分たちが少しお金を出すだけで、海をきれいにしてもらえるから  \n",
    "\n",
    "32. この文章を書いた人は、日本で売られ始めた「海外のファッションの会社」の服や靴について、どのように考えているか。**  \n",
    "1. 海外のファッションに関心を持つ人が増えているので、売れるだろう  \n",
    "2. 環境問題に関心を持つ人が増えているし、デザインも悪くないので、売れるだろう  \n",
    "3. デザインの良さで製品を選ぶ人が増えているので、値段が高くても売れるだろう\n",
    "\"\"\"\n",
    "\n",
    "print(words)\n",
    "\n",
    "# Nodes\n",
    "def generate_question(state: QuestionState):\n",
    "    \"\"\"First LLM call to generate initial question\"\"\"\n",
    "\n",
    "    msg = aws_llm.invoke(f\"You are a japanese teacher. Your job is Read 2 articles with 10-11 lines, with a word count of around 400 words, and answer approximately 3 questions. Only refer to the format, not the content.\"\n",
    "            f\"The vocabulary should be restricted to N3 level, you can refer to the vocabulary in the word list, choosing random words for the questions\"\n",
    "            f\"please refer the question examples following the formal exam paper\"\n",
    "            f\"append the correct answer and explanation of main challenges and why teacher asks this question to candidate in chinese at each question\"\n",
    "            f\"Finally, beautify markdown format\"\n",
    "            f\"topic list: {state['topic']}\"\n",
    "            f\"word list: {words}\"\n",
    "            f\"formal exam paper: {kanji_example}\")\n",
    "    \n",
    "    return {\"question\": msg.content}\n",
    "\n",
    "\n",
    "# Build workflow\n",
    "kanji_workflow = StateGraph(QuestionState)\n",
    "\n",
    "# Add nodes\n",
    "kanji_workflow.add_node(\"generate_question\", generate_question)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "kanji_workflow.add_edge(START, \"generate_question\")\n",
    "kanji_workflow.add_edge(\"generate_question\", END)\n",
    "\n",
    "# Compile\n",
    "kanji_graph = kanji_workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec483e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show workflow\n",
    "#display(Image(kanji_graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c2e1e740fbe6971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T04:56:04.739875Z",
     "start_time": "2025-03-21T04:55:57.132978Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error raised by bedrock service\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langchain_aws\\llms\\bedrock.py\", line 956, in _prepare_input_and_invoke\n",
      "    response = self.client.invoke_model(**request_options)\n",
      "  File \"c:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\botocore\\client.py\", line 570, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\botocore\\context.py\", line 124, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\botocore\\client.py\", line 1031, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ValidationException: An error occurred (ValidationException) when calling the InvokeModel operation: Access to Anthropic models is not allowed from unsupported countries, regions, or territories. Please refer to https://www.anthropic.com/supported-countries for more information on the countries and regions Anthropic currently supports.\n"
     ]
    },
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the InvokeModel operation: Access to Anthropic models is not allowed from unsupported countries, regions, or territories. Please refer to https://www.anthropic.com/supported-countries for more information on the countries and regions Anthropic currently supports.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Invoke\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m kanji = \u001b[43mkanji_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m店で価格を尋ねる | レストランで食べ物を注文する | 交通手段について話す| 天気の状況について話す | 趣味について話す | 店で商品の特徴や価格を尋ねる | スーパーマーケットで買い物をする | レストランで食べ物や飲み物を注文する | カフェでテイクアウトを頼む | コンビニで支払い方法について質問する |  ネットショッピングで商品を選ぶ\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m display(Markdown(kanji[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2669\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[39m\n\u001b[32m   2667\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2668\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2669\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2670\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2673\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2674\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2675\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2679\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2323\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2317\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2318\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2319\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2320\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2321\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2322\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2323\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2324\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2325\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2330\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2331\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:146\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    144\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:600\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    596\u001b[39m config = patch_config(\n\u001b[32m    597\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    598\u001b[39m )\n\u001b[32m    599\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    602\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:365\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mgenerate_question\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_question\u001b[39m(state: QuestionState):\n\u001b[32m     66\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"First LLM call to generate initial question\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     msg = \u001b[43maws_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a japanese teacher. Your job is choose the grammar structure that best fits the context and also assess the ability to read articles, similar to cloze tests.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mThe vocabulary should be restricted to N3 level, you can refer to the vocabulary in the word list, choosing random words for the questions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mplease refer the question examples following the formal exam paper\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mappend the correct answer and explanation of main challenges and why teacher asks this question to candidate in chinese at each question\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFinally, beautify markdown format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtopic list: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mword list: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mwords\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mformal exam paper: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkanji_example\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: msg.content}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:307\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    298\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m     **kwargs: Any,\n\u001b[32m    303\u001b[39m ) -> BaseMessage:\n\u001b[32m    304\u001b[39m     config = ensure_config(config)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    306\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    317\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:843\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    836\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    837\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    840\u001b[39m     **kwargs: Any,\n\u001b[32m    841\u001b[39m ) -> LLMResult:\n\u001b[32m    842\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:683\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    681\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    682\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m         )\n\u001b[32m    690\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    691\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:908\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    912\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langchain_aws\\chat_models\\bedrock.py:721\u001b[39m, in \u001b[36mChatBedrock._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    718\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stop:\n\u001b[32m    719\u001b[39m         params[\u001b[33m\"\u001b[39m\u001b[33mstop_sequences\u001b[39m\u001b[33m\"\u001b[39m] = stop\n\u001b[32m--> \u001b[39m\u001b[32m721\u001b[39m     completion, tool_calls, llm_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_input_and_invoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m        \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatted_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[38;5;66;03m# usage metadata\u001b[39;00m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m usage := llm_output.get(\u001b[33m\"\u001b[39m\u001b[33musage\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langchain_aws\\llms\\bedrock.py:971\u001b[39m, in \u001b[36mBedrockBase._prepare_input_and_invoke\u001b[39m\u001b[34m(self, prompt, system, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    970\u001b[39m         run_manager.on_llm_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    974\u001b[39m     text = enforce_stop_tokens(text, stop)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\langchain_aws\\llms\\bedrock.py:956\u001b[39m, in \u001b[36mBedrockBase._prepare_input_and_invoke\u001b[39m\u001b[34m(self, prompt, system, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    954\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRequest body sent to bedrock: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_options\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    955\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mUsing Bedrock Invoke API to generate response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m (\n\u001b[32m    959\u001b[39m     text,\n\u001b[32m    960\u001b[39m     thinking,\n\u001b[32m   (...)\u001b[39m\u001b[32m    964\u001b[39m     stop_reason,\n\u001b[32m    965\u001b[39m ) = LLMInputOutputAdapter.prepare_output(provider, response).values()\n\u001b[32m    966\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResponse received from Bedrock: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\botocore\\client.py:570\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    567\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    568\u001b[39m     )\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\botocore\\context.py:124\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    123\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HW-BK003\\Desktop\\jlpt_simulator\\.venv\\Lib\\site-packages\\botocore\\client.py:1031\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1027\u001b[39m     error_code = error_info.get(\u001b[33m\"\u001b[39m\u001b[33mQueryErrorCode\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\n\u001b[32m   1028\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1029\u001b[39m     )\n\u001b[32m   1030\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mValidationException\u001b[39m: An error occurred (ValidationException) when calling the InvokeModel operation: Access to Anthropic models is not allowed from unsupported countries, regions, or territories. Please refer to https://www.anthropic.com/supported-countries for more information on the countries and regions Anthropic currently supports.",
      "During task with name 'generate_question' and id '476269bb-c88d-016b-5706-c7617d77dedc'"
     ]
    }
   ],
   "source": [
    "# Invoke\n",
    "kanji = kanji_graph.invoke({\"topic\": \"店で価格を尋ねる | レストランで食べ物を注文する | 交通手段について話す| 天気の状況について話す | 趣味について話す | 店で商品の特徴や価格を尋ねる | スーパーマーケットで買い物をする | レストランで食べ物や飲み物を注文する | カフェでテイクアウトを頼む | コンビニで支払い方法について質問する |  ネットショッピングで商品を選ぶ\"})\n",
    "display(Markdown(kanji[\"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553844c1e99d121c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778d8e10606427f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-21T04:53:14.733662Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
