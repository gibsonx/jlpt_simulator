{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b011bdf967ca7ff",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Language Knowledge (Vocabulary)\n",
    "Duration: 30 minutes\n",
    "Content: This section tests your knowledge of Japanese vocabulary, including kanji readings, orthography, word formation, contextually-defined expressions, paraphrases, and usage\n",
    "It mainly composes following five categories:\n",
    "- ``Reading Kana`` (Pronunciation Questions): Given a kanji word, choose the correct kana reading.\n",
    "- `Writing Kanji` (Writing Questions): Given a word written in kana, choose the correct kanji representation.\n",
    "- `Word Meaning` Selection (Vocabulary Understanding): Choose the most suitable word to fill in the sentence from four options.\n",
    "- `Synonym Replacement`: Select a word that has the same or similar meaning as the underlined word.\n",
    "- `Vocabulary Usage`: Assess the usage of words in actual contexts, choosing the most appropriate word usage, including some common Japanese expressions or fixed phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f526a68a7e73a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:46.881337200Z",
     "start_time": "2025-04-12T09:05:46.846841100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "import uuid\n",
    "from typing import *\n",
    "from langchain_openai import AzureOpenAI,AzureChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from dotenv import load_dotenv\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain_community.embeddings import XinferenceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage,RemoveMessage,HumanMessage,AIMessage,ToolMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain.schema import Document\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58607e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://ai-rolandaws880125ai409947751408.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview\",\n",
    "    api_key=os.environ[\"AZURE_API_KEY\"],\n",
    "    model_name=\"gpt-4o\",\n",
    "    api_version=\"2025-01-01-preview\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "aws_llm = ChatBedrock(\n",
    "    # model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "     model_id=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    model_kwargs=dict(temperature=0.5),\n",
    "    region = \"us-east-2\",\n",
    "    aws_access_key_id=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    aws_secret_access_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:46.893687800Z",
     "start_time": "2025-04-12T09:05:46.853897400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import N3 Vocabulary\n",
    "file_path = '../../Vocab/n3.csv'\n",
    "# Read the CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "words = data.iloc[:, :2].sample(frac=1).reset_index(drop=True)\n",
    "# Display the content of the CSV file\n",
    "words.head()\n",
    "vocab_dict = words.set_index(words.columns[0])[words.columns[1]].to_dict()\n",
    "vocab_dict = json.dumps(vocab_dict, ensure_ascii=False, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1cdce8b1f57ef3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c63b54b5c2a36",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Exam Paper Outline\n",
    "### A. overall thinking the structure of an exam\n",
    "1. distribution of the difficulty \n",
    "2. topics\n",
    "3. reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed5f032dadafac1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Strcuture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5795bb3d95c0cc50",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Kanji 读假名（读音问题）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "252ffacd6ebb7b37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:46.893687800Z",
     "start_time": "2025-04-12T09:05:46.867091900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def online_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---WEB SEARCH---\")\n",
    "    \n",
    "    topic = state['messages'][0].content\n",
    "    \n",
    "    tavily_search_tool = TavilySearch(\n",
    "        max_results=5,\n",
    "        topic=\"news\",\n",
    "        days=1\n",
    "    )\n",
    "    # Web search\n",
    "    docs = tavily_search_tool.invoke({\"query\": topic})\n",
    "    \n",
    "    print(docs)\n",
    "\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs[\"results\"]])\n",
    "    \n",
    "    print(\"Web results: \", web_results)\n",
    "\n",
    "    return {\"documents\": web_results, \"topic\": topic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a966afd733d860d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:46.917155100Z",
     "start_time": "2025-04-12T09:05:46.871842700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# Graph state\n",
    "class QuestionState(TypedDict):\n",
    "    topic: str\n",
    "    question: str\n",
    "    documents: str\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "example = \"\"\"\n",
    "15. 大雪で朝から電車が（　）している。\n",
    "\t1.\t縮小\n",
    "\t2.\t滞在\n",
    "\t3.\t延期\n",
    "\t4.\t運休\n",
    "\n",
    "16. 今日は暑かったので、シャツが（　）でぬれてしまった。\n",
    "\t1.\tいびき\n",
    "\t2.\tあくび\n",
    "\t3.\tあせ\n",
    "\t4.\tいき\n",
    "\n",
    "17. 答えさんに声がよく聞こえるように、（　）を使って話してください。\n",
    "\t1.\tサイレン\n",
    "\t2.\tエンジン\n",
    "\t3.\tノック\n",
    "\t4.\tマイク\n",
    "\n",
    "18. 昨日は早く寝たが、夜中に大きな音がして目が（　）しまった。\n",
    "\t1.\t嫌がって\n",
    "\t2.\t覚めて\n",
    "\t3.\t驚いて\n",
    "\t4.\t怖がって\n",
    "\n",
    "19. 林さんはいつも冗談ばかり言うので、その話も本当かどうか（　）。\n",
    "\t1.\tあやしい\n",
    "\t2.\tおそろしい\n",
    "\t3.\tにくらしい\n",
    "\t4.\tまずしい\n",
    "\n",
    "20. 本日の面接の結果は、1 週間以内にメールで（　）します。\n",
    "\t1.\t広告\n",
    "\t2.\t合図\n",
    "\t3.\t通知\n",
    "\t4.\t伝言\n",
    "\n",
    "21. 兄はいつも（　）シャツを着ているので、遠くにいてもすぐに見つかる。\n",
    "\t1.\t派手な\n",
    "\t2.\t盛んな\n",
    "\t3.\tわがままな\n",
    "\t4.\t身近な\n",
    "\n",
    "22. ここに車を止めることは規則で（　）されていますから、すぐに移動してください。\n",
    "\t1.\t支配\n",
    "\t2.\t英殺\n",
    "\t3.\t禁止\n",
    "\t4.\t批判\n",
    "\n",
    "23. このコートは古いがまだ着られるので、捨ててしまうのは（　）。\n",
    "\t1.\tもったいない\n",
    "\t2.\tしかたない\n",
    "\t3.\tかわいらしい\n",
    "\t4.\tこいかない\n",
    "\n",
    "24. 弟への誕生日プレゼントは、誕生日まで弟に見つからないように、たんすの奥に（　）。\n",
    "\t1.\t包んだ\n",
    "\t2.\t隠した\n",
    "\t3.\t囲んだ\n",
    "\t4.\t閉じた\n",
    "\n",
    "25. 山口さんは今度のパーティーには来られないかもしれないが、（　）誘うつもりだ。\n",
    "\t1.\t十分\n",
    "\t2.\t一応\n",
    "\t3.\tけっこう\n",
    "\t4.\tたいてい\n",
    "\"\"\"\n",
    "\n",
    "# Nodes\n",
    "def question_draft_generator(state: QuestionState):\n",
    "    \"\"\"First LLM call to generate initial question\"\"\"\n",
    "    print(\"---Generator----\")\n",
    "        \n",
    "    search_result = state['documents'],\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"\n",
    "                    You are a Japanese teacher. Your job is to write a vocabulary question for candidates to identify the correct kanji writing of a given word in hiragana for a JLPT N3 level exam paper. The question format follows:\n",
    "                Each question presents a word in hiragana within a sentence, and candidates must choose the correct kanji representation from four options. The options should include one correct kanji form and three distractors that are plausible but incorrect. The JLPT exam paper includes a mix of easy, moderate, and difficult questions to accurately assess the test-taker’s proficiency across different aspects of the language.\n",
    "                    The vocabulary should be restricted to N3 level, use the vocabulary in the `Dictionary` as much as you can.\n",
    "                    Please refer to the question examples following the formal exam paper. please highlight the word to ask candidate with <u><em></em></u>.\n",
    "                    Append the correct answer and explanation of the main challenges on why the teacher asks this question to the candidate in simplified Chinese at each question.\n",
    "                    Finally, output beautiful markdown format.\n",
    "                    Dictionary: {vocab_dict}\n",
    "                    Search result: {search_result}\n",
    "                    Formal exam paper: {example}\n",
    "                \"\"\"\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    \n",
    "    input = { \"topic\" : state['topic'],\n",
    "              \"search_result\": search_result, \n",
    "              \"vocab_dict\": vocab_dict,\n",
    "              \"example\": example,\n",
    "              \"messages\": state[\"messages\"]\n",
    "              }\n",
    "    # final_message = prompt.format_messages(**input)\n",
    "    # print(final_message)\n",
    "    \n",
    "    generate = prompt | azure_llm\n",
    "    \n",
    "    msg = generate.invoke(input=input)\n",
    "    \n",
    "    \n",
    "    return {\"question\": msg.content, \"messages\": [AIMessage(content=msg.content)] }\n",
    "\n",
    "\n",
    "def reflection_node(state: QuestionState) -> QuestionState:\n",
    "    print(\"---REVISOR---\")\n",
    "    \n",
    "    # Other messages we need to adjust\n",
    "    cls_map = {\"ai\": HumanMessage, \"human\": AIMessage}\n",
    "    # First message is the original user request. We hold it the same for all nodes\n",
    "    translated = [state[\"messages\"][0]] + [\n",
    "        cls_map[msg.type](content=msg.content) for msg in state[\"messages\"][1:]\n",
    "    ]\n",
    "\n",
    "    reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"you are a Japanese language educator reviewing a JLPT exam paper. Generate critique and recommendations for the user's submission.\n",
    "            the review focuses on content accuracy and question quality. \n",
    "            - For content accuracy, you must verify that the grammar and vocabulary questions accurately reflect the appropriate JLPT N3 level, ensuring the reading passages are clear, relevant, and appropriately challenging. \n",
    "            - For question quality, you must ensure all questions are clearly worded and free from ambiguity to comprehensively assess different language skills, and confirm that the difficulty level of the questions matches the intended JLPT N3 level.\n",
    "            - During detailed refinement, you check the format and presentation of the paper, ensuring it is well-organized and the instructions are clear and concise. you also ensure the content is culturally appropriate and relevant to Japanese language and culture.\n",
    "            - Finally, you make give feedback, providing detailed recommendations, including requests.If you think the exam paper is good enough, you just say \"GOOD ENOUGH\"\n",
    "            \"\"\"\n",
    "        ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    reflect = reflection_prompt | azure_llm\n",
    "    \n",
    "    res = reflect.invoke(translated)\n",
    "    \n",
    "    print(res.content)\n",
    "    \n",
    "    # We treat the output of this as human feedback for the generator\n",
    "    return {\"messages\": [HumanMessage(content=res.content)]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e802dc904d791c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:47.226967100Z",
     "start_time": "2025-04-12T09:05:46.881337200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build workflow\n",
    "builder = StateGraph(QuestionState)\n",
    "\n",
    "builder.add_node(\"online_search\", online_search)\n",
    "builder.add_node(\"generator\", question_draft_generator)\n",
    "builder.add_node(\"reflector\", reflection_node)\n",
    "# Add nodes\n",
    "\n",
    "def should_continue(state: QuestionState):\n",
    "    if state[\"messages\"]:\n",
    "        if len(state[\"messages\"]) > 6: \n",
    "            print(\"--- Reach the Maximum Round ---\")\n",
    "            return END\n",
    "        elif \"GOOD ENOUGH\" in state[\"messages\"][-1].content:\n",
    "            print(\"--- AI Reviser feels Good Enough ---\")\n",
    "            return END\n",
    "    return \"generator\"\n",
    "\n",
    "# Add edges to connect nodes\n",
    "builder.add_edge(START, \"online_search\")\n",
    "builder.add_edge(\"online_search\", \"generator\")\n",
    "builder.add_edge(\"generator\",\"reflector\")\n",
    "# \n",
    "builder.add_conditional_edges(\"reflector\", should_continue)\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile\n",
    "kanji_graph = builder.compile()\n",
    "\n",
    "# Show workflow\n",
    "# display(Image(kanji_graph.get_graph().draw_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec5f157c924be8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:47.233071800Z",
     "start_time": "2025-04-12T09:05:47.226967100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HW-BK003\\AppData\\Local\\Temp\\ipykernel_16172\\846002302.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  word = f\"{row[0]}({row[1]})\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'用心(ようじん)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = words.iloc[1]\n",
    "word = f\"{row[0]}({row[1]})\"\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c2e1e740fbe6971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:05:47.238098800Z",
     "start_time": "2025-04-12T09:05:47.233071800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Debug the Conversation\n",
    "# for event in kanji_graph.stream(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             HumanMessage(\n",
    "#                 content=word\n",
    "#             )\n",
    "#         ],\n",
    "#     },\n",
    "#     config={\"configurable\": {\"thread_id\": \"1\"}},\n",
    "# ):\n",
    "#     print(event)\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553844c1e99d121c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:06:11.173729Z",
     "start_time": "2025-04-12T09:05:47.238098800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---WEB SEARCH---\n",
      "{'query': '用心(ようじん)', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': '用心／要心（ようじん）とは？ 意味・読み方・使い方をわかりやすく解説 - goo国語辞書', 'url': 'https://dictionary.goo.ne.jp/word/用心/', 'content': '用心／要心（ようじん）とは。意味や使い方、類語をわかりやすく解説。[名](スル)1 心をくばること。気をつけること。「風邪をひかないように—する」2 万一に備えて注意・警戒を怠らないこと。「火の—」「—の悪い家」 - goo国語辞書は30万9千件語以上を収録。', 'score': 0.82117355, 'raw_content': None}, {'title': '用心 - Wiktionary, the free dictionary', 'url': 'https://en.wiktionary.org/wiki/用心', 'content': '用心しない: ようじんしない: yōjin shinai: Negative continuative 用心せず: ようじんせず: yōjin sezu: Formal 用心します: ようじんします: yōjin shimasu: Perfective 用心した: ようじんした: yōjin shita: Conjunctive 用心して: ようじんして: yōjin shite: Hypothetical conditional 用心すれば', 'score': 0.79769903, 'raw_content': None}, {'title': '「用心」とは？意味や例文や読み方や由来について解説!｜コトバスタ', 'url': 'https://kotobasta.com/13435/', 'content': '「用心」は「ようじん」と読みます。 この言葉は、特に日本語において非常に重要な役割を持っています。 特に何かに注意を払う必要があるときや、危険を察知したときに自然と使われる表現です。', 'score': 0.7568076, 'raw_content': None}, {'title': '用心(ヨウジン)とは？ 意味や使い方 - コトバンク', 'url': 'https://kotobank.jp/word/用心-653092', 'content': '用心の補助注記 元来「用心」と書くが、中世後期以降「要心」「要慎」等の表記が見える。 これは平安末以降「用」の 字音 「 ヨウ 」と「要」の字音「エウ」との区別がなくなったことによる 混同 から生じたあて字と考えられる。', 'score': 0.71040785, 'raw_content': None}, {'title': '【用心】と【注意】と【留意】の意味の違いと使い方の例文 | 例文買取センター', 'url': 'https://reibuncnt.jp/709', 'content': '似た意味を持つ「用心」（読み方：ようじん）と「注意」（読み方：ちゅうい）と「留意」（読み方：りゅうい）の違いを例文を使って分かりやすく解説しているページです。どれを使えば日本語として正しい言葉となるのか、迷った方はこのページの使い分け方を参考にしてみてください。', 'score': 0.63234437, 'raw_content': None}], 'response_time': 1.84}\n",
      "Web results:  用心／要心（ようじん）とは。意味や使い方、類語をわかりやすく解説。[名](スル)1 心をくばること。気をつけること。「風邪をひかないように—する」2 万一に備えて注意・警戒を怠らないこと。「火の—」「—の悪い家」 - goo国語辞書は30万9千件語以上を収録。\n",
      "用心しない: ようじんしない: yōjin shinai: Negative continuative 用心せず: ようじんせず: yōjin sezu: Formal 用心します: ようじんします: yōjin shimasu: Perfective 用心した: ようじんした: yōjin shita: Conjunctive 用心して: ようじんして: yōjin shite: Hypothetical conditional 用心すれば\n",
      "「用心」は「ようじん」と読みます。 この言葉は、特に日本語において非常に重要な役割を持っています。 特に何かに注意を払う必要があるときや、危険を察知したときに自然と使われる表現です。\n",
      "用心の補助注記 元来「用心」と書くが、中世後期以降「要心」「要慎」等の表記が見える。 これは平安末以降「用」の 字音 「 ヨウ 」と「要」の字音「エウ」との区別がなくなったことによる 混同 から生じたあて字と考えられる。\n",
      "似た意味を持つ「用心」（読み方：ようじん）と「注意」（読み方：ちゅうい）と「留意」（読み方：りゅうい）の違いを例文を使って分かりやすく解説しているページです。どれを使えば日本語として正しい言葉となるのか、迷った方はこのページの使い分け方を参考にしてみてください。\n",
      "---Generator----\n",
      "---REVISOR---\n",
      "### Review of Vocabulary Question: 用心 (ようじん)\n",
      "\n",
      "#### Content Accuracy:\n",
      "The vocabulary question is appropriate for the JLPT N3 level. The word \"用心\" (ようじん) is commonly used in Japanese to mean \"care\" or \"caution,\" and the context provided in the sentence (\"風邪をひかないように、しっかり用心してください\") is clear and relevant. The explanation provided is accurate and correctly highlights the subtle differences between similar terms like \"注意\" and \"留意.\" Additionally, the inclusion of \"要心,\" which is not a valid Japanese word, serves as a good distractor for test-takers.\n",
      "\n",
      "#### Question Quality:\n",
      "The question is well-worded and free of ambiguity. The sentence is concise and provides sufficient context for test-takers to understand the meaning of \"用心.\" The distractor options are appropriate and challenge the test-taker’s ability to distinguish between similar terms. The difficulty level is well-suited to the JLPT N3 level, as it requires understanding both the meaning and the correct kanji usage.\n",
      "\n",
      "#### Format and Presentation:\n",
      "The format of the question is clear and organized. The use of underlining and italics to highlight the target word is effective and visually distinct. The instructions are concise, and the multiple-choice options are presented in a clean and easy-to-read manner. The explanation is thorough and provides a good breakdown of the reasoning behind the correct answer.\n",
      "\n",
      "#### Cultural Appropriateness:\n",
      "The content is culturally appropriate and relevant to Japanese language learners. The example sentence uses a common and relatable scenario (preventing illness), which aligns well with everyday Japanese usage.\n",
      "\n",
      "---\n",
      "\n",
      "### Feedback and Recommendations:\n",
      "1. **Enhance Explanation Depth:** While the explanation is clear, you could expand slightly on why \"注意\" and \"留意\" are not suitable in this context. For example:\n",
      "   - \"注意\" often implies paying attention to something specific or being vigilant, whereas \"用心\" emphasizes taking precautionary measures to avoid danger.\n",
      "   - \"留意\" is more formal and often used in written contexts, making it less suitable for the conversational tone of the sentence.\n",
      "\n",
      "2. **Add Furigana for Kanji:** To make the question more accessible for N3-level learners, consider adding furigana to the kanji in the explanation (e.g., 注意 (ちゅうい), 留意 (りゅうい)).\n",
      "\n",
      "3. **Include More Context in the Sentence:** While the sentence is clear, adding slight elaboration could make it more engaging and realistic, such as:\n",
      "   - \"風邪をひかないように、寒い日はしっかり用心してください。\"  \n",
      "   This provides a bit more context and makes the sentence feel more natural.\n",
      "\n",
      "---\n",
      "\n",
      "### Overall Evaluation:\n",
      "GOOD ENOUGH\n",
      "--- AI Reviser feels Good Enough ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Vocabulary Question: 用心 (ようじん)\n",
       "\n",
       "#### Question:\n",
       "風邪をひかないように、しっかり<u><em>ようじん</em></u>してください。\n",
       "\n",
       "1. 用心  \n",
       "2. 注意  \n",
       "3. 要心  \n",
       "4. 留意  \n",
       "\n",
       "---\n",
       "\n",
       "#### Correct Answer:\n",
       "**1. 用心**\n",
       "\n",
       "---\n",
       "\n",
       "#### Explanation (简体中文):\n",
       "正确答案是“用心”。“用心”表示小心、注意，特别是在防止某些危险或问题时使用。其他选项如“注意”和“留意”虽然也有类似的含义，但它们通常用于更具体或不同的上下文；“要心”是错误的写法，不是标准日语词汇。\n",
       "\n",
       "这道题的难点在于考察考生对日语中近义词的细微区别的掌握，以及对正确汉字的选择能力。这是JLPT N3考试中常见的题型，旨在测试考生的词汇和汉字知识。\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kanji = kanji_graph.invoke(\n",
    "    {\n",
    "       \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=word\n",
    "                )\n",
    "            ],\n",
    "        },\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "display(Markdown(kanji[\"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778d8e10606427f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:06:11.182472400Z",
     "start_time": "2025-04-12T09:06:11.173729Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
